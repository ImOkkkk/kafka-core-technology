## 1.Kafka入门

### 1.1 消息引擎系统ABC

**消息引擎系统**：系统A发送消息给消息引擎系统，系统B从消息引擎系统中读取A发送是消息。

- 传输消息的格式：纯二进制的字节序列，消息还是结构化的，只是在使用之前都要将其转换成二进制的字节序列。
- 传输协议
  - 点对点模型：系统A发送的消息只能被系统B接收，其它任何系统都不能读取A发送的消息。
  - 发布/订阅模型：发送方称为发布者(Publisher)，接收方称为订阅者(Subscriber)，这个模型可能存在多个发布者向相同的主题(Topic)发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。

**填谷削峰**

引入Kafka后，上游订单服务不在直接与服务进行交互。当新订单生成后它仅仅是向Kafka Broker发送一条订单消息即可。下游的各个子服务订阅Kafka中的对应主题，并实时从该主题的各自分区(Partition)中获取到订单消息进行处理，从而实现了上游订单服务与下游订单处理服务的解耦。当出现秒杀业务时，Kafka能够将瞬时增加的订单流量全部以消息形式保存在对应的主题中，既不影响上游服务的TPS，同时也给下游子服务留出了充足的时间去消费它们。

### 1.2 Kafka术语

**生产者(Producer)**和**消费者(Consumer)**统称为**客户端(Clients)**，Kafka的服务器端由被称为**Broker**的服务进程构成，即一个Kafka集群由多个Broker组成，Broker负责接收和处理客户端发送过来的请求。以及对消息进行持久化。(Borker分散运行在不同的机器上)。

相同的数据拷贝到多台机器上，这些相同的数据拷贝在Kafka中称为**副本(Replica)**。**领导者副本(Leader Replica)**：对外提供副本(与客户端程序进行交互)；**追随者副本(Follower Replica)**：被动的追随领导者副本，不能与外界进行交互。**副本的工作机制**：生产者总是向领导者副本写消息，而消费者总是从领导者副本读消息，追随者副本，只做一件事：向领导者副本发送请求，请求领导者把最新生成的消息发给它(保持与领导者同步)。

Kafka中的分区机制指的是将每个主题划分成多个**分区(Partition)**，每个分区是一组有序的消息日志。生产者生产的每条消息**只会被发送到一个分区中**。副本是在分区这个层级定义的，每个分区下可以配置若干个副本，其中只能有1个领导者副本和N-1个追随者副本。生产者向分区写入消息，每条消息在分区中的位置信息由一个叫**位移(Offset)**的数据来表征，分区位移总是从0开始。

**Kafka的三层消息架构**

- 主题层：每个主题可以配置M个分区，而每个分区又可以配置N个副本。
- 分区层：每个分区的N个副本只能有一个充当领导者角色，对外提供服务；其它N-1个副本是追随者副本，只是提供数据冗余之用。
- 消息层：分区中包含若干条消息，每条消息的位移从0开始，依次递增。

客户端程序只能与分区的领导者副本进行交互。

**持久化数据**

Kafka使用消息日志(Log)来保存数据，一个日志就是磁盘上一个只能追加写(Append-only)消息的物理文件(只能追加，避免了缓慢的随机I/O操作，改为性能较好的顺序I/O写操作)。Kafka会定期的删除消息以回收磁盘，**日志段(Log Segment)机制**：一个日志近一步细分成多个日志段，并将老的日志段封存起来，后台定时任务会定期的检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。

**消费者组(Consumer Group)**，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都都只会被组内的一个消费者实例消费，其它消费者实例不能消费它。多个消费者实例同时消费，加速整个消费端的吞吐量(TPS)。

**重平衡(Rebalance)**：组内某个实例挂掉了，Kafka能够自动检测到，然后把这个Failed实例之前负责的分区转移给其它活着的消费者。

**消费者位移(Consumer Offser)**：记录了消费者在消费消息过程中消费到了分区的哪个位置上。上面的"位移"表征的是分区内的消息位置，它是不变的，即一旦消息被成功写到到一个分区上，它的位移值就是固定的了。而消费者位移则不同，它可能是随时变化的，是消费者消费进度的指示器，另外每个消费者有着自己的消费者位移。

**总结**

- 消息：Record，Kafka处理的主要对象。
- 主题：Topic，主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。
- 分区：Partition，一个有序不变的消息序列，每个主题下可以有多个分区。
- 消息位移：Offset，表示分区中每条消息的位置信息，是一个单调递增且不变的值。
- 副本：Replica，Kafka中同一条消息能够被拷贝多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。
- 生产者：Producer，向主题发布新消息的应用程序。
- 消费者：Consumer，从主题订阅新消息的应用程序。
- 消费者位移：Consumer Offset，表征消费者消费进度，每个消费者都有自己的消费者位移。
- 消费者组：Consumer Group，多个消费者实例共同组成一个组，同时消费多个分区以实现高吞吐。
- 重平衡：Rebalance，消费组内某个消费者实例挂掉后，其它消费者实例自动重新分配订阅主题分区的过程，是Kafka消费者端实现高可用的重要手段。

![](./img/Kafka.png)

### 1.3 Kafka只是消息引擎系统吗？

Kafka是消息引擎系统，也是一个分布式流处理平台。

- 提供一套API实现生产者和消费者；
- 降低网络传输和磁盘存储开销；
- 实现高伸缩性架构。

## 2.Kafka的基本使用

### 2.1 Kafka线上集群部署方案怎么做？

**操作系统**

Linux更加适合Kafka

- I/O模型的使用：阻塞式I/O、非阻塞式I/O、I/O多路复用、信号驱动I/O、异步I/O，Kafka客户端使用了Java的selector，selector在Linux上的实现机制是epoll。
- 数据网络传输效率：零拷贝
- 社区支持度

**磁盘**

Kafka使用方式多是顺序读写，规避了机械硬盘随机读写操作慢的缺点。

磁盘阵列：提供冗余的磁盘存储空间；提供负载均衡。Kafka自己实现了冗余机制提供高可靠性，通过分区实现负载均衡。

**磁盘容量**

每天1亿条1KB大小的消息，保存两份且留存两周：1亿 * 1KB * 2 /1000/1000 = 200GB，其它数据(如索引数据)，预留10%，220GB * 14 = 3TB，假设数据压缩比0.75，0.75 * 3 = 2.25TB

- 新增消息数
- 消息留存时间
- 平均消息大小
- 备份数
- 是否启用压缩

**带宽**

带宽1Gbps(千兆网)，1小时内处理1TB的业务数据(1024 * 1024 / 3600 * 8每秒需要处理2336Mb的数据)，假设每台Kafka机器没有混布其他服务，Kafka用到70%的带宽资源，通常再额外留出2/3的资源，即单台服务器使用带宽1000 * 70% / 3 = 240Mbps。2336/240 = 10，如果消息还需要额外复制两份，那么服务器台数还需要x3，即30台。

![](./img/Kafka部署方案.jfif)

### 2.2 重要的集群参数配置

**Broker端参数**

- log.dirs：Broker需要使用的若干个文件目录路径(无默认值)

  配置多个路径，CSV格式(即用逗号分隔的多个路径，如`/home/kafka1,/home/kafka2,/home/kafka3`)，这些目录挂载到不同的物理磁盘上更好：

  - 提升读写性能：比起单块磁盘，多块物理磁盘同时读写数据有更高的吞吐量。
  - 能实现故障转移：即Failover，1.1之前Kafka Broker使用的任何一块磁盘挂掉了，整个Broker进程都会被关闭，1.1之后坏掉的磁盘上的数据会自动的转移到其它正常的磁盘上。

- log.dir：只能表示单个路径，用来补充上一个参数。

ZooKeeper是一个分布式协调框架，负责协调管理并保存Kafka集群的所有元数据信息，比如集群都有哪些Broker在运行，创建了哪些Topic，每个Topic都有多少分区以及这些分区的Leader副本都在哪些机器上等信息。

- zookeeper.connect：也是一个CSV格式的参数，如`zk1:2181,zk2:2181,zk3:2181`。2181 是 ZooKeeper 的默认端口。假如有两套Kafka集群(kafka1和kafka2)，通过chroot(别名)，参数可以指定为`zk1:2181,zk2:2181,zk3:2181/kafka1`和`zk1:2181,zk2:2181,zk3:2181/kafka2`。

客户端程序或其他Broker如何与该Broker进行通信的设置

- listeners：监听器，告诉外部连接者要通过什么协议访问指定主机名和端口开放的Kafka1服务

  若干个逗号分隔的三元组，每个三元组格式为`<协议名称，主机名，端口号>`。协议名称可能是标准的名字，如PLAINTEXT(明文传输)、SSL(使用SSL或TLS加密传输)等；也可能是自定义的协议名字如`CONTROLLER：//localhost:9092`。

  一旦自定义了协议名称，还必须指定listener.security.protocol.map告诉这个协议底层使用里哪种安全协议，比如指定`listener.security.protocol.map=CONTROLLER:PLAINTEXT表示CONTROLLER`这个自定义协议底层使用明文不加密传输数据。

  **Broker端和Client端应用配置中应全部填写主机名。**

- advertised.listeners：Advertised：宣称的、公布的，即这组Broker用于对外发布的。

关于Topic管理

- auto.create.topics.enable：是否允许自动创建Topic，建议设置为false。
- unclean.leader.election.enable：是否允许Unclean Leader选举，建议false。true：允许从"落后"的副本里选择Leader(可能会丢失数据)；false：不允许"落后"太多的副本竞选Leader，分区不可用。
- auto.leader.rebalance.enable：是否允许Kafka定期进行Leader重选举，建议false。

数据保留方面

- log.retention.{hour|minutes|ms}：控制一条消息被保存多久，优先级：ms>minutes>hour。log.retention.hour：168，表示保存7天的数据，自动删除7天前的数据。
- log.retention.bytes：指定Broker为消息保存的总磁盘容量大小，默认-1(不限制)。多租户Kafka集群时用处比较大。
- message.max.bytes：控制Broker能够接收的最大消息大小，默认1000012(不到1MB)，建议调大(仅仅衡量Broker能够处理的最大消息大小，即使设置大也不会耗费磁盘空间)。

**Topic级别参数**

Topic级别参数会覆盖Broker参数的值，每个 Topic 都能设置自己的参数值。

- retention.ms：规定了该Topic消息被保存的时长，默认7天。
- retention.bytes：规定了为该Topic预留多大的磁盘空间，默认值-1。
- max.message.bytes：Kafka Broker能够正常接收该Topic最大消息大小。

怎么设置Topic级别的参数

1. 创建Topic时进行设置

   需要将交易数据发送到Kafka进行处理，需要保存近半年的交易数据，同时数据很多(不超过5MB)，创建Topic：`--config`后面指定想要设置的Topic级别参数

   ```sh
   bin/kafka-topics.sh--bootstrap-serverlocalhost:9092--create--topictransaction--partitions1--replication-factor1--config retention.ms=15552000000--configmax.message.bytes=5242880
   ```
   
2. **修改Topic时设置**

   修改发送消息最大值10MB

   ```sh
   bin/kafka-configs.sh--zookeeperlocalhost:2181--entity-typetopics--entity-nametransaction--alter--add-config max.message.bytes=10485760
   ```

**JVM参数**

- KAFKA_HEAP_OPTS：指定堆大小，默认1GB，建议设为6GB，Kafka Broker与客户端进行交互时会在JVM堆上创建大量的ByteBuffer。
- KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数，Java8使用默认的G1即可。

启动Kafka Broker之前，设置这两个环境变量：

```sh
$> export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g
$> export  KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true
$> bin/kafka-server-start.sh config/server.properties
```

**操作系统参数**

- 文件描述符限制：ulimit -n 1000000
- 文件系统类型：XFS
- Swappiness：swap调优，设为0时，当物理内存耗尽时，就会触发OOM killer，随机挑选一个组件kill掉，不会给用户任何预警。使用swap空间，至少可以观测到Broker性能急剧下降，从而进一步调优和诊断问题。建议将Swappiness配置成一个解决0但不为0的值，如1。
- 提交时间(Flush落盘时间)：向Kafka发送数据，数据被写入到操作系统的页缓存(Page Cache)上就认为成功了，随后操作系统会根据LRU算法会定期将页缓存上的"脏"数据落盘到物理磁盘上，这个"定期"就是由提交时间来确定的，默认5秒，可以适当增加提交间隔来降低物理磁盘的写操作。(页缓存数据在写入到磁盘前宕机，数据丢失：Kafka在软件层面已经提供了多副本的冗余机制)

