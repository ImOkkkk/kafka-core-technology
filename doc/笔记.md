## 1.Kafka入门

### 1.1 消息引擎系统ABC

**消息引擎系统**：系统A发送消息给消息引擎系统，系统B从消息引擎系统中读取A发送是消息。

- 传输消息的格式：纯二进制的字节序列，消息还是结构化的，只是在使用之前都要将其转换成二进制的字节序列。
- 传输协议
  - 点对点模型：系统A发送的消息只能被系统B接收，其它任何系统都不能读取A发送的消息。
  - 发布/订阅模型：发送方称为发布者(Publisher)，接收方称为订阅者(Subscriber)，这个模型可能存在多个发布者向相同的主题(Topic)发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。

**填谷削峰**

引入Kafka后，上游订单服务不在直接与服务进行交互。当新订单生成后它仅仅是向Kafka Broker发送一条订单消息即可。下游的各个子服务订阅Kafka中的对应主题，并实时从该主题的各自分区(Partition)中获取到订单消息进行处理，从而实现了上游订单服务与下游订单处理服务的解耦。当出现秒杀业务时，Kafka能够将瞬时增加的订单流量全部以消息形式保存在对应的主题中，既不影响上游服务的TPS，同时也给下游子服务留出了充足的时间去消费它们。

### 1.2 Kafka术语

**生产者(Producer)**和**消费者(Consumer)**统称为**客户端(Clients)**，Kafka的服务器端由被称为**Broker**的服务进程构成，即一个Kafka集群由多个Broker组成，Broker负责接收和处理客户端发送过来的请求。以及对消息进行持久化。(Borker分散运行在不同的机器上)。

相同的数据拷贝到多台机器上，这些相同的数据拷贝在Kafka中称为**副本(Replica)**。**领导者副本(Leader Replica)**：对外提供副本(与客户端程序进行交互)；**追随者副本(Follower Replica)**：被动的追随领导者副本，不能与外界进行交互。**副本的工作机制**：生产者总是向领导者副本写消息，而消费者总是从领导者副本读消息，追随者副本，只做一件事：向领导者副本发送请求，请求领导者把最新生成的消息发给它(保持与领导者同步)。

Kafka中的分区机制指的是将每个主题划分成多个**分区(Partition)**，每个分区是一组有序的消息日志。生产者生产的每条消息**只会被发送到一个分区中**。副本是在分区这个层级定义的，每个分区下可以配置若干个副本，其中只能有1个领导者副本和N-1个追随者副本。生产者向分区写入消息，每条消息在分区中的位置信息由一个叫**位移(Offset)**的数据来表征，分区位移总是从0开始。

**Kafka的三层消息架构**

- 主题层：每个主题可以配置M个分区，而每个分区又可以配置N个副本。
- 分区层：每个分区的N个副本只能有一个充当领导者角色，对外提供服务；其它N-1个副本是追随者副本，只是提供数据冗余之用。
- 消息层：分区中包含若干条消息，每条消息的位移从0开始，依次递增。

客户端程序只能与分区的领导者副本进行交互。

**持久化数据**

Kafka使用消息日志(Log)来保存数据，一个日志就是磁盘上一个只能追加写(Append-only)消息的物理文件(只能追加，避免了缓慢的随机I/O操作，改为性能较好的顺序I/O写操作)。Kafka会定期的删除消息以回收磁盘，**日志段(Log Segment)机制**：一个日志近一步细分成多个日志段，并将老的日志段封存起来，后台定时任务会定期的检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。

**消费者组(Consumer Group)**，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都都只会被组内的一个消费者实例消费，其它消费者实例不能消费它。多个消费者实例同时消费，加速整个消费端的吞吐量(TPS)。

**重平衡(Rebalance)**：组内某个实例挂掉了，Kafka能够自动检测到，然后把这个Failed实例之前负责的分区转移给其它活着的消费者。

**消费者位移(Consumer Offser)**：记录了消费者在消费消息过程中消费到了分区的哪个位置上。上面的"位移"表征的是分区内的消息位置，它是不变的，即一旦消息被成功写到到一个分区上，它的位移值就是固定的了。而消费者位移则不同，它可能是随时变化的，是消费者消费进度的指示器，另外每个消费者有着自己的消费者位移。

**总结**

- 消息：Record，Kafka处理的主要对象。
- 主题：Topic，主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。
- 分区：Partition，一个有序不变的消息序列，每个主题下可以有多个分区。
- 消息位移：Offset，表示分区中每条消息的位置信息，是一个单调递增且不变的值。
- 副本：Replica，Kafka中同一条消息能够被拷贝多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。
- 生产者：Producer，向主题发布新消息的应用程序。
- 消费者：Consumer，从主题订阅新消息的应用程序。
- 消费者位移：Consumer Offset，表征消费者消费进度，每个消费者都有自己的消费者位移。
- 消费者组：Consumer Group，多个消费者实例共同组成一个组，同时消费多个分区以实现高吞吐。
- 重平衡：Rebalance，消费组内某个消费者实例挂掉后，其它消费者实例自动重新分配订阅主题分区的过程，是Kafka消费者端实现高可用的重要手段。

![](./img/Kafka.png)

### 1.3 Kafka只是消息引擎系统吗？

Kafka是消息引擎系统，也是一个分布式流处理平台。

- 提供一套API实现生产者和消费者；
- 降低网络传输和磁盘存储开销；
- 实现高伸缩性架构。

## 2.Kafka的基本使用

### 2.1 Kafka线上集群部署方案怎么做？

**操作系统**

Linux更加适合Kafka

- I/O模型的使用：阻塞式I/O、非阻塞式I/O、I/O多路复用、信号驱动I/O、异步I/O，Kafka客户端使用了Java的selector，selector在Linux上的实现机制是epoll。
- 数据网络传输效率：零拷贝
- 社区支持度

**磁盘**

Kafka使用方式多是顺序读写，规避了机械硬盘随机读写操作慢的缺点。

磁盘阵列：提供冗余的磁盘存储空间；提供负载均衡。Kafka自己实现了冗余机制提供高可靠性，通过分区实现负载均衡。

**磁盘容量**

每天1亿条1KB大小的消息，保存两份且留存两周：1亿 * 1KB * 2 /1000/1000 = 200GB，其它数据(如索引数据)，预留10%，220GB * 14 = 3TB，假设数据压缩比0.75，0.75 * 3 = 2.25TB

- 新增消息数
- 消息留存时间
- 平均消息大小
- 备份数
- 是否启用压缩

**带宽**

带宽1Gbps(千兆网)，1小时内处理1TB的业务数据(1024 * 1024 / 3600 * 8每秒需要处理2336Mb的数据)，假设每台Kafka机器没有混布其他服务，Kafka用到70%的带宽资源，通常再额外留出2/3的资源，即单台服务器使用带宽1000 * 70% / 3 = 240Mbps。2336/240 = 10，如果消息还需要额外复制两份，那么服务器台数还需要x3，即30台。

![](./img/Kafka部署方案.jfif)

### 2.2 重要的集群参数配置

**Broker端参数**

- log.dirs：Broker需要使用的若干个文件目录路径(无默认值)

  配置多个路径，CSV格式(即用逗号分隔的多个路径，如`/home/kafka1,/home/kafka2,/home/kafka3`)，这些目录挂载到不同的物理磁盘上更好：

  - 提升读写性能：比起单块磁盘，多块物理磁盘同时读写数据有更高的吞吐量。
  - 能实现故障转移：即Failover，1.1之前Kafka Broker使用的任何一块磁盘挂掉了，整个Broker进程都会被关闭，1.1之后坏掉的磁盘上的数据会自动的转移到其它正常的磁盘上。

- log.dir：只能表示单个路径，用来补充上一个参数。

ZooKeeper是一个分布式协调框架，负责协调管理并保存Kafka集群的所有元数据信息，比如集群都有哪些Broker在运行，创建了哪些Topic，每个Topic都有多少分区以及这些分区的Leader副本都在哪些机器上等信息。

- zookeeper.connect：也是一个CSV格式的参数，如`zk1:2181,zk2:2181,zk3:2181`。2181 是 ZooKeeper 的默认端口。假如有两套Kafka集群(kafka1和kafka2)，通过chroot(别名)，参数可以指定为`zk1:2181,zk2:2181,zk3:2181/kafka1`和`zk1:2181,zk2:2181,zk3:2181/kafka2`。

客户端程序或其他Broker如何与该Broker进行通信的设置

- listeners：监听器，告诉外部连接者要通过什么协议访问指定主机名和端口开放的Kafka1服务

  若干个逗号分隔的三元组，每个三元组格式为`<协议名称，主机名，端口号>`。协议名称可能是标准的名字，如PLAINTEXT(明文传输)、SSL(使用SSL或TLS加密传输)等；也可能是自定义的协议名字如`CONTROLLER：//localhost:9092`。

  一旦自定义了协议名称，还必须指定listener.security.protocol.map告诉这个协议底层使用里哪种安全协议，比如指定`listener.security.protocol.map=CONTROLLER:PLAINTEXT表示CONTROLLER`这个自定义协议底层使用明文不加密传输数据。

  **Broker端和Client端应用配置中应全部填写主机名。**

- advertised.listeners：Advertised：宣称的、公布的，即这组Broker用于对外发布的。

关于Topic管理

- auto.create.topics.enable：是否允许自动创建Topic，建议设置为false。
- unclean.leader.election.enable：是否允许Unclean Leader选举，建议false。true：允许从"落后"的副本里选择Leader(可能会丢失数据)；false：不允许"落后"太多的副本竞选Leader，分区不可用。
- auto.leader.rebalance.enable：是否允许Kafka定期进行Leader重选举，建议false。

数据保留方面

- log.retention.{hour|minutes|ms}：控制一条消息被保存多久，优先级：ms>minutes>hour。log.retention.hour：168，表示保存7天的数据，自动删除7天前的数据。
- log.retention.bytes：指定Broker为消息保存的总磁盘容量大小，默认-1(不限制)。多租户Kafka集群时用处比较大。
- message.max.bytes：控制Broker能够接收的最大消息大小，默认1000012(不到1MB)，建议调大(仅仅衡量Broker能够处理的最大消息大小，即使设置大也不会耗费磁盘空间)。

**Topic级别参数**

Topic级别参数会覆盖Broker参数的值，每个 Topic 都能设置自己的参数值。

- retention.ms：规定了该Topic消息被保存的时长，默认7天。
- retention.bytes：规定了为该Topic预留多大的磁盘空间，默认值-1。
- max.message.bytes：Kafka Broker能够正常接收该Topic最大消息大小。

怎么设置Topic级别的参数

1. 创建Topic时进行设置

   需要将交易数据发送到Kafka进行处理，需要保存近半年的交易数据，同时数据很多(不超过5MB)，创建Topic：`--config`后面指定想要设置的Topic级别参数

   ```sh
   bin/kafka-topics.sh--bootstrap-serverlocalhost:9092--create--topictransaction--partitions1--replication-factor1--config retention.ms=15552000000--configmax.message.bytes=5242880
   ```
   
2. **修改Topic时设置**

   修改发送消息最大值10MB

   ```sh
   bin/kafka-configs.sh--zookeeperlocalhost:2181--entity-typetopics--entity-nametransaction--alter--add-config max.message.bytes=10485760
   ```

**JVM参数**

- KAFKA_HEAP_OPTS：指定堆大小，默认1GB，建议设为6GB，Kafka Broker与客户端进行交互时会在JVM堆上创建大量的ByteBuffer。
- KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数，Java8使用默认的G1即可。

启动Kafka Broker之前，设置这两个环境变量：

```sh
$> export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g
$> export  KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true
$> bin/kafka-server-start.sh config/server.properties
```

**操作系统参数**

- 文件描述符限制：ulimit -n 1000000
- 文件系统类型：XFS
- Swappiness：swap调优，设为0时，当物理内存耗尽时，就会触发OOM killer，随机挑选一个组件kill掉，不会给用户任何预警。使用swap空间，至少可以观测到Broker性能急剧下降，从而进一步调优和诊断问题。建议将Swappiness配置成一个解决0但不为0的值，如1。
- 提交时间(Flush落盘时间)：向Kafka发送数据，数据被写入到操作系统的页缓存(Page Cache)上就认为成功了，随后操作系统会根据LRU算法会定期将页缓存上的"脏"数据落盘到物理磁盘上，这个"定期"就是由提交时间来确定的，默认5秒，可以适当增加提交间隔来降低物理磁盘的写操作。(页缓存数据在写入到磁盘前宕机，数据丢失：Kafka在软件层面已经提供了多副本的冗余机制)

## 3.客户端实践与原理刨析

### 3.1 生产者消息分区机制原理刨析

**为什么分区？**

Kafka消息组织：主题-分区-消息。主题下的每条消息只会保存在某一个分区中，不会在多个分区中被保存多份。

![](./img/Kafka消息结构.png)

分区的作用是提供负载均衡的能力，为了实现系统的高伸缩性。不同的分区能够被放置到不同节点的机器上，而数据的读写操作也是针对分区这个粒度进行的，这样每个节点的机器都能独立的执行各自分区的读写请求处理，并且，还可以通过添加新的节点机器来增加整体系统的吞吐量。

**分区策略**

决定生产者将消息发送到哪个分区的算法

- 自定义分区策略

  配置生产者端的参数`partitioner.class`，编写一个具体的类实现`org.apache.kafka.clients.producer.Partitioner`接口，重写partition方法：

  ```java
  int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);
  ```

  `topic、key、keyBytes、value`和`valueBytes`都属于消息数据，`cluste`r则是集群信息(比如当前Kafka集群共有多少主题，多少Broker等)。

- 轮询策略(Round-robin)

  顺序分配，如一个主题下有3个分区，那么第一条消息被发送到分区0，第二条被发送到分区1，第三条被发送到分区2，以此类推。当生产第 4 条消息时又会重新开始，即将其分配到分区0。

  ![](./img/轮询策略.png)

  Kafka Java生产者默认提供的分区策略，有着非常优秀的负载均衡表现，它总是能保证消息最大限度的被平均分配到所有分区上。

- 随机策略(Randomness)

  随机的将消息放置到任意一个分区上，力求将数据均匀的打散到各个分区，但实际表现上要略逊于轮询策略，新版本中被轮询策略取代。

  ![](./img/随机策略.png)

  实现随机策略版的partition方法

  ```java
      @Override
      public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
          List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
          return ThreadLocalRandom.current().nextInt(partitions.size());
      }
  ```

  先计算出该主题总的分区数，然后随机返回一个小于它的正整数。

- 按消息键保序策略(Key-ordering)

  一旦消息被定义了Key，那么就可以保证同一个Key的所有消息都进入到相同的分区，由于每个分区下的消息处理都是有序的，故这个策略被称为按消息键保序策略。

  ![](./img/按消息键保序策略.png)

  实现按消息键保序策略版的partition方法

  ```java
      @Override
      public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
          List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
          return Math.abs(key.hashCode())%partitions.size();
      }
  ```

  Kafka默认分区策略实际上同时实现了两种策略：如果指定了Key，那么默认实现按消息键保序策略，否则使用轮询策略。

- 其他分区策略

  - 基于地理位置的分区策略(针对跨城市、国家的大规模Kafka集群)

    从所有分区中找出Leader副本在南方的所有分区，然后随机挑选一个进行消息发送。

    ```java
     @Override
        public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
            List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
            return partitions.stream().filter(p -> isSouth(p.leader().host())).map(PartitionInfo::partition).findAny().get();
        }
    ```


### 3.2 生产者压缩算法

压缩(compression)，用时间去换空间，即用CPU时间去换磁盘空间或网络I/O传输量，希望以较小的CPU开销带来更少的磁盘占用或更少的网络I/O传输。

**怎么压缩？**

Kafka的消息层次分为两层：消息集合(message set)及消息(message)。一个消息集合中包含若干条日志项(record item)，而日志项才是真正封装消息的地方。Kafka底层的消息日志由一系列消息集合日志组成。Kafka通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。

引入V2版本：

1. 把消息的公共部分抽取出来放到外层消息集合里，不用每条消息都保存这些信息了。
2. 对整个消息集合进行压缩。

**何时压缩？**

Kafka中，压缩可能发生在两个地方：生产者端和Broker端。

生产者程序中配置compression.type参数即表示启用指定类型的压缩算法。

如何构建一个开启GZIP的Producer对象：

```java
        Properties properties = new Properties();
        properties.put("bootstrap.servers","127.0.0.1:9092");
        properties.put("acks","all");
        properties.put("key.serializer","org.apache.kafka.common.serialization.StringSerializer");
        properties.put("value.serializer","org.apache.kafka.common.serialization.StringSerializer");
        // 开启GZIP压缩
        properties.put("compression.type","gzip");

        Producer<String,String> producer = new KafkaProducer<String, String>(properties);
```

` properties.put("compression.type","gzip")`表明该Producer的压缩算法使用的是GZIP，这样Producer的压缩算法使用的是GZIP。这样Producer启动后生产的每个消息集合都是经GZIP压缩过的，故而能节省网络传输带宽及Kafka Broker端的磁盘占用。

大部分情况下Broker端不需要再重新压缩，两种例外情况：

1. Broker端指定了和Producer端不同的压缩算法(表现为CPU使用率飙升)

2. Broker端发生了消息格式转换

   主要为了兼容老版本的消费者程序，除了消息的压缩和解压缩，还会丧失"零拷贝"特性。

**何时解压缩？**

Producer发送压缩消息到Broker后，当Consumer程序请求这部分消息时，Broker原样发送出去，消息到达Consumer端后，由Consumer自行解压缩还原成之前的消息。

Kafka会将启用了哪种压缩算法封装到消息集合中，**Producer端压缩、Broker端保持、Consumer端解压缩**。

除了在Consumer端解压缩，Broker端也会进行解压缩，对消息执行各种验证。

**各种压缩算法对比**

Kafka支持的压缩算法：GZIP、Snappy、LZ4、Zstandard(2.1.0引入，简写为zstd)算法。

衡量压缩算法的优劣：压缩比(压缩前占空间/压缩后占空间)，压缩/解压缩吞吐量(每秒压缩/解压缩多少MB数据)

![img](img/各种压缩算法对比.png)

**最佳实践**

启用压缩的时间：CPU资源充足，带宽资源有限，如果客户端机器CPU资源有很多富余，开启zstd压缩，能极大地节省网络资源消耗。

解压缩：一旦启用压缩，解压缩是不可避免的，要尽量规避那些意料之外的解压缩，如兼容老版本而引入的解压缩就属于这类。

### 3.3 无消息丢失配置怎么实现？

Kafka只对"**已提交**"的消息(committed message)做**有限度的持久化保证**。

**已提交**：Kafka**若干个**Broker成功的接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。

**"消息丢失"案例**

- 生产者程序丢失数据

  Kafka Producer是异步发送消息的，即producer.send(msg)，会立即返回，此时不能认为消息发送已成功完成。(网络抖动，导致消息压根没发送到Broker端；消息本身不合格导致Broker拒绝接收，如消息太大，超过Broker的承受能力。)

  Producer永远要使用带有回调通知的发送API，即不要使用producer.send(msg)，而要使用producer.send(msg, callback)，一旦出现消息提交失败的情况，可以有针对性的进行处理。如果是因为那些瞬时错误，让Producer重试；如果消息不合格，可以调整消息格式再次发送。

- 消费者程序丢失数据

  Consumer端丢失数据主要体现在Consumer端要消费的消息不见了。Consumer程序有个"位移"的概念，表示的是这个Consumer当前消费到的Topic分区的位置。

  比如对于Consumer A而言，它当前的位移值就是9，Consumer B的位移值是11。
  
  ![img](img/Consumer端位移数据.png)
  
  **维持先消费消息，再更新位移的顺序**，能最大限度地保证消息不丢失。(可能会带来消息的重复处理)
  
  Consumer程序从Kafka获取到消息后开启了多个线程异步处理消息，而Consumer程序自动地向前更新位移。假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于Consumer而言实际上是丢失了。
  
  **如果是多线程异步处理消费消息，Consumer程序不要开启自动提交位移，而是要应用程序手动提交位移**。
  
  **最佳实践**
  
  1. 不要使用producer.send(msg)，而要使用producer.send(msg，callback)。
  2. 设置acks=all，Producer参数，代表对"已提交"消息的定义，设置成all，表明所有副本Broker都要接收到消息，该消息才算是"已提交"。
  3. 设置retries为一个较大的值，Producer参数，对应Producer自动重试。当出现网络瞬时抖动时，消息可能发送失败，此时配置了retries>0的Producer能够自动重试消息发送，避免消息丢失。
  4. 设置unclean.leader.election.enable=false，Broker参数，控制哪些Broker有资格竞选分区的Leader。如果一个Broker落后原先的Leader太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。
  5. 设置replication.factor>=3，Broker参数，最好将消息多保存几份。
  6. 设置min.insync.replicas>1，Broker参数，控制消息至少要被写入到多少个副本才算"已提交"。
  7. replication.factor>min.insync.replicas，如果两者相等，那么只要有一个副本挂了，整个分区就无法正常工作了，通常replication.factor=min.insync.replicas+1。
  8. 确保消息消费完成再提交。Consumer端参数enable.auto.commit，最好设置为false，并采用手动提交位移的方式。

### 3.4 Kafka拦截器

**什么是拦截器？**

允许应用程序在不修改逻辑的情况下，动态的是实现一组可插拔的事件处理逻辑链。它能够在主业务操作的前后多个时间点上插入对应的"拦截"逻辑。

Spring MVC拦截器工作原理：

![](img/SpringMVC拦截器工作原理.png)

拦截器1和拦截器2分别在请求发送之前、发送之后以及完成三个地方插入了对应的处理逻辑。

Kafka可以在消息处理的前后多个时点动态植入到不同的处理逻辑，比如在消息发送之前或者消息被消费后。

**Kafka拦截器**

**Kafka拦截器分为生产者拦截器和消费者拦截器**。生产者拦截器允许在发送消息前及消息提交成功之后植入拦截器逻辑；而消费者拦截器支持在消费消息前以及提交位移后编写特定的逻辑。这两种拦截器都支持链的方式，即可以将一组拦截器串联成一个大的拦截器，Kafka会按照添加顺序执行拦截器逻辑。

生产者和消费者两端有一个相同的参数，名字叫interceptor.class，指定一组类的列表，每个类就是特定逻辑的拦截器的实现类。假设第一个拦截器的完整类路径是 com.yourcompany.kafkaproject.interceptors.AddTimeStampInterceptor，第二个类是 com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor，需要在Producer端指定逻辑：

```
        Properties properties = new Properties();
        // 配置拦截器
        interceptors.add("org.imokkkk.interceptors.AddTimestampInterceptor"); // 拦截器 1
        interceptors.add("org.imokkkk.interceptors.UpdateCounterInterceptor"); // 拦截器 2
        properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);
        Producer<String,String> producer = new KafkaProducer<String, String>(properties);
```

生产者拦截器：

实现org.apache.kafka.clients.producer.ProducerInterceptor 接口，核心方法：

1. onSend：该方法会在消息发送之前被调用。
2. onAcknowledgement：该方法会在消息成功提交或发送失败之后被调用，onAcknowledgement的调用要早于callback回调通知。onAcknowledgement与onSend方法不在同一个线程中。

消费者拦截器：

实现 org.apache.kafka.clients.consumer.ConsumerInterceptor 接口，核心方法：

1. onConsume：该方法在消息返回Consumer程序之前调用。
2. onCommit：Consumer在提交位移之后调用该方法。

**典型使用场景**

**Kafka拦截器可以应用于包括客户端监控、端到端系统性能监测、消息审计等场景。**

监控一条消息从生产到最后消费的端到端延时：通过实现拦截器的逻辑以及可插拔的机制，能够快速地观测、验证以及监控集群间的客户端性能指标，特别是能够从具体的消息层面上去收集数据。

消息审计

**案例**

记录业务消息从被生产出来到最后被消费的平均总时长是多少。

生产者拦截器：

```java
public class AvgLatencyProducerInterceptor implements ProducerInterceptor {

    private Jedis jedis; // 省略 Jedis 初始化

    @Override
    public ProducerRecord onSend(ProducerRecord record) {
        // 在发送消息前更新总的已发送消息数
        jedis.incr("totalSentMessage");
        return record;
    }

    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {

    }

    @Override
    public void close() {

    }

    @Override
    public void configure(Map<String, ?> configs) {

    }
}
```

消费者拦截器：

```java
public class AvgLatencyConsumerInterceptor implements ConsumerInterceptor<String, String> {

    private Jedis jedis; // 省略 Jedis 初始化

    @Override
    public ConsumerRecords onConsume(ConsumerRecords<String, String> records) {
        long latency = 0L;
        for (ConsumerRecord<String, String> record : records) {
            // 当前时间减去封装在消息中的创建时间
            latency += (System.currentTimeMillis() - record.timestamp());
        }
        // 这批消息总的端到端处理延时
        jedis.incrBy("totalLatency", latency);
        // 总延时
        long totalLatency = Long.parseLong(jedis.get("totalLatency"));
        // 总消息数
        long totalSentMsgs = Long.parseLong(jedis.get("totalSentMessage"));
        // 端到端消息的平均处理延时
        jedis.set("avgLatency", String.valueOf(totalLatency / totalSentMsgs));
        return records;
    }

    @Override
    public void close() {

    }

    @Override
    public void onCommit(Map offsets) {

    }

    @Override
    public void configure(Map<String, ?> configs) {

    }
}
```

